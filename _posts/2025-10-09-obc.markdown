---
layout: post
title:  "OBCache: Optimal Brain KV Cache Pruning for Efficient Long-Context LLM Inference"
date:   2025-10-09 22:21:59 +00:00
image: /images/obcache.png
categories: research
author: "Yuzhe Gu"
authors: "<strong>Yuzhe Gu</strong>, Xiyu Liang, Jiaojiao Zhao, Enmao Diao"
venue: "arXiv preprint"
paper: https://arxiv.org/abs/2510.07651
code: https://github.com/DreamSoul-AI/OBCache/tree/main
---
We propose Optimal Brain Cache (OBCache), a principled framework that formulates KV cache eviction as a layer-wise structured pruning problem. OBCache quantifies token saliency by measuring the perturbation in attention outputs induced by pruning tokens, with closed-form scores derived for isolated keys, isolated values, and joint key-value pairs.